{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "notebookV4.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "yesiKYEf4kr2"
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsoCHtpcoJHT"
   },
   "source": [
    "## Download the dataset\n",
    "Getting dataset from Kaggle requires kaggle.json file. Obtain it from the Account page."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fS3dxMXR4MTu",
    "outputId": "be5efb65-a71c-4ff0-8b42-9a93ad141b04"
   },
   "source": [
    "%mkdir /root/.kaggle/"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tnpv8IIn4fnp"
   },
   "source": [
    "%cp kaggle.json /root/.kaggle/"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ts4TzK14ufs",
    "outputId": "6d41f77a-3650-4c28-d8ce-7fffab300757"
   },
   "source": [
    "!kaggle datasets download -d mengcius/cinic10"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Downloading cinic10.zip to /content\n",
      " 99% 750M/754M [00:08<00:00, 57.6MB/s]\n",
      "100% 754M/754M [00:09<00:00, 87.7MB/s]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JKPm-BVe48EG"
   },
   "source": [
    "import shutil\n",
    "shutil.unpack_archive(\"cinic10.zip\", \"/content\")"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5-8gXAvTNl6"
   },
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gwXyCP1X2kr3"
   },
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9GR9lx0ne4gm"
   },
   "source": [
    "# Hyperparameters\r\n",
    "image_size = 32  # for VGG and Resnet, assign 224\r\n",
    "color_channel = 3\r\n",
    "\r\n",
    "input_shape = (image_size, image_size, color_channel)\r\n",
    "\r\n",
    "traindir = \"/content/train\"\r\n",
    "testdir = \"/content/test\""
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGSYFpjhf8Xf",
    "outputId": "7cae46c3-3591-4411-84fb-15dd6f2a0f3d"
   },
   "source": [
    "# get all classes from dataset\r\n",
    "categories = []\r\n",
    "for dir in os.listdir(traindir):\r\n",
    "  categories.append(dir)\r\n",
    "categories"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['automobile',\n",
       " 'airplane',\n",
       " 'bird',\n",
       " 'ship',\n",
       " 'dog',\n",
       " 'deer',\n",
       " 'truck',\n",
       " 'frog',\n",
       " 'cat',\n",
       " 'horse']"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GqNLZM29w08F",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d5e0322b-15e3-40b3-dd0e-a1afaeefecd4"
   },
   "source": [
    "# VGG and Resnet requires 224x224 images, therefore more memory\r\n",
    "# will be used. To save memory, maximum max_images images for each class \r\n",
    "# can be used\r\n",
    "max_images = 300 \r\n",
    "iterations = 0\r\n",
    "\r\n",
    "train_data, test_data = [], []\r\n",
    "\r\n",
    "# read train and test datasets\r\n",
    "for category in categories:\r\n",
    "\r\n",
    "    train_path = os.path.join(traindir, category)  \r\n",
    "    test_path = os.path.join(testdir, category)\r\n",
    "\r\n",
    "    category_index = categories.index(category)\r\n",
    "\r\n",
    "    # iterate through train images\r\n",
    "    for img in tqdm(os.listdir(train_path)):\r\n",
    "\r\n",
    "      # set limit for maximum number of images\r\n",
    "      # due to memory limitations\r\n",
    "      #iterations += 1\r\n",
    "      #if iterations > max_images:\r\n",
    "      #  break\r\n",
    "      \r\n",
    "      image_data = cv2.imread(os.path.join(train_path, img))\r\n",
    "      # resized = cv2.resize(image_data, (image_size, image_size)) \r\n",
    "      train_data.append([image_data, category_index])\r\n",
    "\r\n",
    "    iterations = 0\r\n",
    "\r\n",
    "    # iterate through test images\r\n",
    "    for img in tqdm(os.listdir(test_path)):\r\n",
    "\r\n",
    "      # set limit for maximum number of images\r\n",
    "      # due to memory limitations\r\n",
    "      #iterations += 1\r\n",
    "      #if iterations > max_images:\r\n",
    "      #  break\r\n",
    "\r\n",
    "      image_data = cv2.imread(os.path.join(test_path, img))\r\n",
    "      # resized = cv2.resize(image_data, (image_size, image_size)) \r\n",
    "      test_data.append([image_data, category_index])\r\n",
    "    iterations = 0\r\n",
    "\r\n",
    "print('\\n')\r\n",
    "print('Training data length:', len(train_data))\r\n",
    "print('Test data length:', len(test_data))"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [00:00<00:00, 9746.64it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 9600.08it/s]\n",
      "100%|██████████| 9000/9000 [00:01<00:00, 8903.22it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 9248.29it/s]\n",
      "100%|██████████| 9000/9000 [00:01<00:00, 7916.27it/s]\n",
      "100%|██████████| 9000/9000 [00:01<00:00, 7170.13it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 9473.79it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 9666.64it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 9712.02it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 9310.45it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 9524.63it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 9363.18it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 10185.45it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 9812.12it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 9291.11it/s]\n",
      "100%|██████████| 9000/9000 [00:01<00:00, 8389.63it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 9600.16it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 9379.84it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 10373.17it/s]\n",
      "100%|██████████| 9000/9000 [00:00<00:00, 9823.52it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data length: 90000\n",
      "Test data length: 90000\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJXo6fhV6ZQI",
    "outputId": "7ae41b64-c7e5-4516-a515-95a2c2c8a38d"
   },
   "source": [
    "# shuffle the data\n",
    "random.shuffle(train_data)\n",
    "for sample in train_data[:10]:\n",
    "  print(sample[1])"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kqFXFSHuw1Kn"
   },
   "source": [
    "X_train, X_test, y_train, y_test = [], [], [], []\r\n",
    "\r\n",
    "for features, label in train_data:\r\n",
    "    X_train.append(features)\r\n",
    "    y_train.append(label)\r\n",
    "\r\n",
    "for features, label in test_data:\r\n",
    "    X_test.append(features)\r\n",
    "    y_test.append(label)\r\n",
    "\r\n",
    "# reshape new ndarrays to desired image size\r\n",
    "X_train = np.array(X_train).reshape(-1, image_size, image_size, color_channel)\r\n",
    "X_test = np.array(X_test).reshape(-1, image_size, image_size, color_channel)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K1Lza2reeL2N"
   },
   "source": [
    "# clear variables from colab to save memory\n",
    "%reset_selective -f \"^train_data$\"\n",
    "%reset_selective -f \"^test_data$\""
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-UEquh9SADUx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a2705998-aa6d-43ce-b20e-27915d0da7af"
   },
   "source": [
    "# Normalization\r\n",
    "X_train = np.array(X_train/255.0)\r\n",
    "# X_test will be normalized later\r\n",
    "\r\n",
    "y_train = np.array(y_train)\r\n",
    "y_test = np.array(y_test)\r\n",
    "\r\n",
    "# one-hot encoding\r\n",
    "y_train = to_categorical(y_train, len(categories))\r\n",
    "y_test = to_categorical(y_test, len(categories))\r\n",
    "\r\n",
    "print('X_train:', X_train.shape)\r\n",
    "print('X_test:', X_test.shape)\r\n",
    "print('y_train:', y_train.shape)\r\n",
    "print('y_test:', y_test.shape)"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "X_train: (90000, 32, 32, 3)\n",
      "X_test: (90000, 32, 32, 3)\n",
      "y_train: (90000, 10)\n",
      "y_test: (90000, 10)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cd9Ae_6f7We0"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yesiKYEf4kr2"
   },
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mrjcnw9y2kr8",
    "outputId": "f12d4d2c-9081-46fd-82ee-64cd055ca53e"
   },
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(50, kernel_size=(3, 3), kernel_initializer='GlorotNormal', \n",
    "                 input_shape=input_shape, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(75, kernel_size=(3, 3), kernel_initializer='GlorotNormal', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(125, kernel_size=(3, 3), kernel_initializer='GlorotNormal', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(len(categories), activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=\"adam\", \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 50)        1400      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 75)        33825     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 75)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 12, 12, 125)       84500     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 125)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 6, 125)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4500)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                45010     \n",
      "=================================================================\n",
      "Total params: 164,735\n",
      "Trainable params: 164,735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SSvVohn_aAP",
    "outputId": "51c49301-a7f3-4e6c-cea2-648039305e17"
   },
   "source": [
    "model.fit(X_train, y_train, batch_size=128,  epochs=10)"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "704/704 [==============================] - 10s 13ms/step - loss: 1.8171 - accuracy: 0.3275\n",
      "Epoch 2/10\n",
      "704/704 [==============================] - 9s 13ms/step - loss: 1.3757 - accuracy: 0.5101\n",
      "Epoch 3/10\n",
      "704/704 [==============================] - 9s 13ms/step - loss: 1.2198 - accuracy: 0.5650\n",
      "Epoch 4/10\n",
      "704/704 [==============================] - 9s 13ms/step - loss: 1.1330 - accuracy: 0.6008\n",
      "Epoch 5/10\n",
      "704/704 [==============================] - 9s 13ms/step - loss: 1.0737 - accuracy: 0.6213\n",
      "Epoch 6/10\n",
      "704/704 [==============================] - 9s 13ms/step - loss: 1.0301 - accuracy: 0.6363\n",
      "Epoch 7/10\n",
      "704/704 [==============================] - 9s 13ms/step - loss: 0.9942 - accuracy: 0.6517\n",
      "Epoch 8/10\n",
      "704/704 [==============================] - 9s 13ms/step - loss: 0.9656 - accuracy: 0.6592\n",
      "Epoch 9/10\n",
      "704/704 [==============================] - 9s 13ms/step - loss: 0.9380 - accuracy: 0.6685\n",
      "Epoch 10/10\n",
      "704/704 [==============================] - 9s 13ms/step - loss: 0.9112 - accuracy: 0.6798\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f40b54fc8d0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SP0kURjm124N"
   },
   "source": [
    "# Normalize the test data\r\n",
    "X_test = np.array(X_test/255.0)"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIq8uEORNZA8",
    "outputId": "5197408e-693c-4b5f-8132-86c838e4cabb"
   },
   "source": [
    "# Calculate prediction\r\n",
    "y_pred = model.predict(X_test)\r\n",
    "y_pred_indices = np.argmax(y_pred, axis = 1)\r\n",
    "y_test_indices = np.argmax(y_test, axis = 1)\r\n",
    "\r\n",
    "print(confusion_matrix(y_test_indices, y_pred_indices))\r\n",
    "print(classification_report(y_test_indices, y_pred_indices))"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[[6381  309   69  534   31   24 1454   29   59  110]\n",
      " [ 202 6753  365 1125   21   54  255   30   69  126]\n",
      " [  80  551 5582  616  236  426   62  634  578  235]\n",
      " [ 250  665  265 7123   47   63  309   71  121   86]\n",
      " [ 136  239  916  450 3055  855  140  247 2022  940]\n",
      " [  54  283  939  445  531 4235  113  316  896 1188]\n",
      " [1559  320   68  609   41   40 6125   21   86  131]\n",
      " [  55   72  794  235  114  184   35 6576  862   73]\n",
      " [  75  176  898  425  813  548  129  644 4950  342]\n",
      " [  93  226  350  258  385  515  179   25  402 6567]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.71      9000\n",
      "           1       0.70      0.75      0.73      9000\n",
      "           2       0.54      0.62      0.58      9000\n",
      "           3       0.60      0.79      0.68      9000\n",
      "           4       0.58      0.34      0.43      9000\n",
      "           5       0.61      0.47      0.53      9000\n",
      "           6       0.70      0.68      0.69      9000\n",
      "           7       0.77      0.73      0.75      9000\n",
      "           8       0.49      0.55      0.52      9000\n",
      "           9       0.67      0.73      0.70      9000\n",
      "\n",
      "    accuracy                           0.64     90000\n",
      "   macro avg       0.64      0.64      0.63     90000\n",
      "weighted avg       0.64      0.64      0.63     90000\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvUkqKh4eu9-"
   },
   "source": [
    "### VGG-16\n",
    "\n",
    "This model requires input shape of 224x224x3, therefore resize the images before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ytI7AXT_oH5Y",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3713181b-bb98-4ae1-ea38-b2928c7c3d5c"
   },
   "source": [
    "model = VGG16(weights=\"imagenet\")\r\n",
    "\r\n",
    "# remove output layer\r\n",
    "model = Model(inputs=model.inputs, \r\n",
    "                  outputs=model.layers[-2].output)\r\n",
    "\r\n",
    "# add 1 fully-connected and 1 prediction layer\r\n",
    "fc = Dense(1024, activation='relu', name='fc')(model.layers[-2].output)\r\n",
    "pred = Dense(len(categories), activation='softmax', name='prediction')(fc)\r\n",
    "\r\n",
    "# create new model with VGG16 and our custom layers\r\n",
    "myModel = Model(model.input, pred)\r\n",
    "\r\n",
    "# make only last 4 layers trainable\r\n",
    "for i in range(0, 19):\r\n",
    "  myModel.layers[i].trainable=False\r\n",
    "\r\n",
    "myModel.compile(optimizer='adam', \r\n",
    "                loss='categorical_crossentropy',\r\n",
    "                metrics=[\"accuracy\"])\r\n",
    "\r\n",
    "myModel.summary()"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 121,684,810\n",
      "Trainable params: 106,970,122\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8tJAISS7GmTs"
   },
   "source": [
    "myModel.fit(X_train, y_train, batch_size=32, epochs=10)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ePPMUlJhIVkW"
   },
   "source": [
    "# clear varibales from colab to save memory\n",
    "%reset_selective -f \"^X_train$\"\n",
    "%reset_selective -f \"^y_train$\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g1-jXlKbGmFp"
   },
   "source": [
    "# Normalize the test data\r\n",
    "X_test = np.array(X_test/255.0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "504oXq82pdG2"
   },
   "source": [
    "# Calculate prediction with tests data\r\n",
    "y_pred = model.predict(X_test)\r\n",
    "y_pred_indices = np.argmax(y_pred, axis = 1)\r\n",
    "y_test_indices = np.argmax(y_test, axis = 1)\r\n",
    "\r\n",
    "print(confusion_matrix(y_test_indices, y_pred_indices))\r\n",
    "print(classification_report(y_test_indices, y_pred_indices))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fel6x0PmN82o"
   },
   "source": [
    "### Resnet-50\n",
    "\n",
    "This model also requires input shape of 224x224x3, therefore resize the images to the specified size before training."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-domhYgtPmBt"
   },
   "source": [
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# add 1 fully-connected and 1 prediction\n",
    "fc = Dense(1024, name='fc')(model.layers[-2].output)\n",
    "pred = Dense(len(categories), activation='softmax', name='prediction')(fc)\n",
    "\n",
    "# create new model with VGG16 and our custom layers\n",
    "myModel = Model(model.input, pred)\n",
    "\n",
    "# make resnet layers untrainable\n",
    "# only last one will be trainable\n",
    "for i in range(0, 175):\n",
    "  myModel.layers[i].trainable=False\n",
    "\n",
    "myModel.compile(optimizer='adam', \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "myModel.summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ujnVJBPbHfg3"
   },
   "source": [
    "myModel.fit(X_train, y_train, batch_size=32, epochs=10)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wW4AkFD3SoQL"
   },
   "source": [
    "# clear varibales from colab to save memory\n",
    "%reset_selective -f \"^X_train$\"\n",
    "%reset_selective -f \"^y_train$\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bw2uYNpRJnTy"
   },
   "source": [
    "# Normalize the test data\r\n",
    "X_test = np.array(X_test/255.0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Fh2JX9KOTfbt"
   },
   "source": [
    "# Calculate prediction with tests data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_indices = np.argmax(y_pred, axis = 1)\n",
    "y_test_indices = np.argmax(y_test, axis = 1)\n",
    "\n",
    "print(confusion_matrix(y_test_indices, y_pred_indices))\n",
    "print(classification_report(y_test_indices, y_pred_indices))"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}